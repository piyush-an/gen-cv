{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c6d52d2",
   "metadata": {},
   "source": [
    "# Azure Computer Vision 4 (Florence)\n",
    "\n",
    "## Fashion Visual Search - Gradio App\n",
    "\n",
    "![Image](florence.jpg)\n",
    "\n",
    "![Image](fashionheader.png)\n",
    "\n",
    "<br>\n",
    "<i>Note: this image was generated with Azure Open AI Dall-e 2</i>\n",
    "\n",
    "### Visual search with vector embeddings\n",
    "**Vector embeddings** are a way of representing content such as text or images as vectors of real numbers in a high-dimensional space. These embeddings are often learned from large amounts of textual and visual data using machine learning algorithms like neural networks. Each dimension of the vector corresponds to a different feature or attribute of the content, such as its semantic meaning, syntactic role, or context in which it commonly appears. By representing content as vectors, we can perform mathematical operations on them to compare their similarity or use them as inputs to machine learning models.\n",
    "\n",
    "![Image](embeddings.jpg)\n",
    "\n",
    "\n",
    "### Business applications\n",
    "- **Digital asset management**: Image retrieval can be used to manage large collections of digital images, such as in museums, archives, or online galleries. Users can search for images based on visual features and retrieve the images that match their criteria.\n",
    "- **Medical image retrieval**: Image retrieval can be used in medical imaging to search for images based on their diagnostic features or disease patterns. This can help doctors or researchers to identify similar cases or track disease progression.\n",
    "- **Security and surveillance**: Image retrieval can be used in security and surveillance systems to search for images based on specific features or patterns, such as in, people & object tracking, or threat detection.\n",
    "- **Forensic image retrieval**: Image retrieval can be used in forensic investigations to search for images based on their visual content or metadata, such as in cases of cyber-crime.\n",
    "- **E-commerce**: Image retrieval can be used in online shopping applications to search for similar products based on their features or descriptions or provide recommendations based on previous purchases.\n",
    "- **Fashion and design**: Image retrieval can be used in fashion and design to search for images based on their visual features, such as color, pattern, or texture. This can help designers or retailers to identify similar products or trends.\n",
    "\n",
    "### Visual Search Process\n",
    "![Image](fashionprocess.png)\n",
    "\n",
    "### Image Retrieval with Azure Computer Vision Documentation\n",
    "- https://learn.microsoft.com/en-us/azure/cognitive-services/computer-vision/concept-image-retrieval\n",
    "- https://learn.microsoft.com/en-us/azure/cognitive-services/computer-vision/how-to/image-retrieval\n",
    "\n",
    "### Demo images\n",
    "Demo images are a sample of this collection of images: https://www.kaggle.com/competitions/h-and-m-personalized-fashion-recommendations/data\n",
    "<br><br>\n",
    "> Serge Retkowsky | Microsoft | https://github.com/retkowsky | 3rd of May, 2023"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ebb0cb4",
   "metadata": {},
   "source": [
    "## 1. <a name=\"chapt1\"></a> Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71b8f060",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nb_black'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m get_ipython()\u001b[39m.\u001b[39;49mrun_line_magic(\u001b[39m'\u001b[39;49m\u001b[39mload_ext\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mnb_black\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2369\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2367\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mlocal_ns\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2368\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2369\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2371\u001b[0m \u001b[39m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2372\u001b[0m \u001b[39m# when using magics with decodator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2373\u001b[0m \u001b[39m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2374\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(fn, magic\u001b[39m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[39mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/IPython/core/magics/extension.py:33\u001b[0m, in \u001b[0;36mExtensionMagics.load_ext\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m module_str:\n\u001b[1;32m     32\u001b[0m     \u001b[39mraise\u001b[39;00m UsageError(\u001b[39m'\u001b[39m\u001b[39mMissing module name.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshell\u001b[39m.\u001b[39;49mextension_manager\u001b[39m.\u001b[39;49mload_extension(module_str)\n\u001b[1;32m     35\u001b[0m \u001b[39mif\u001b[39;00m res \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39malready loaded\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     36\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m extension is already loaded. To reload it, use:\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m module_str)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/IPython/core/extensions.py:76\u001b[0m, in \u001b[0;36mExtensionManager.load_extension\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Load an IPython extension by its module name.\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \n\u001b[1;32m     71\u001b[0m \u001b[39mReturns the string \"already loaded\" if the extension is already loaded,\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[39m\"no load function\" if the module doesn't have a load_ipython_extension\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[39mfunction, or None if it succeeded.\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_extension(module_str)\n\u001b[1;32m     77\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mModuleNotFoundError\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     \u001b[39mif\u001b[39;00m module_str \u001b[39min\u001b[39;00m BUILTINS_EXTS:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/IPython/core/extensions.py:91\u001b[0m, in \u001b[0;36mExtensionManager._load_extension\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshell\u001b[39m.\u001b[39mbuiltin_trap:\n\u001b[1;32m     90\u001b[0m     \u001b[39mif\u001b[39;00m module_str \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m sys\u001b[39m.\u001b[39mmodules:\n\u001b[0;32m---> 91\u001b[0m         mod \u001b[39m=\u001b[39m import_module(module_str)\n\u001b[1;32m     92\u001b[0m     mod \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mmodules[module_str]\n\u001b[1;32m     93\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_load_ipython_extension(mod):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/lib/python3.11/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1206\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1178\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1142\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nb_black'"
     ]
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bb13529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import glob\n",
    "import gradio as gr\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cac7df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Azure CV endpoint and key from the azure.env file\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"azure.env\")\n",
    "key = os.getenv(\"azure_cv_key\")\n",
    "endpoint = os.getenv(\"azure_cv_endpoint\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bdc50670",
   "metadata": {},
   "source": [
    "### Importing our specific functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "404e371f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python file: azure.py Date: Thu Jul  6 18:00:33 2023\n"
     ]
    }
   ],
   "source": [
    "pyfile = \"azure.py\"\n",
    "\n",
    "print(\"Python file:\", pyfile, \"Date:\", time.ctime(os.path.getmtime(pyfile)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a800ed7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure import (\n",
    "    get_cosine_similarity,\n",
    "    image_embedding,\n",
    "    text_embedding,\n",
    "    remove_background,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10fd6a08",
   "metadata": {},
   "source": [
    "## 2. <a name=\"chapt2\"></a> Informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87e9c307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.11.1 (main, Mar 24 2023, 00:55:06) [GCC 11.3.0]'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78e6b097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today is 2023-07-06 19:28:19.842189\n"
     ]
    }
   ],
   "source": [
    "print(\"Today is\", datetime.datetime.today())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "395e3c5c",
   "metadata": {},
   "source": [
    "## 3. <a name=\"chapt3\"></a> Our products images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9e90893",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_DIR = \"fashion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77de30d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory of images: fashion\n",
      "Total number of catalog images = 1,473\n"
     ]
    }
   ],
   "source": [
    "image_files = glob.glob(IMAGES_DIR + \"/*\")\n",
    "\n",
    "print(\"Directory of images:\", IMAGES_DIR)\n",
    "print(\"Total number of catalog images =\", \"{:,}\".format(len(image_files)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec0c3ece",
   "metadata": {},
   "source": [
    "## 4. <a name=\"chapt4\"></a> Loading vector embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e45aa4e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['json/img_embed_06Jul2023_191005.json']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JSON_DIR = \"json\"\n",
    "\n",
    "glob.glob(JSON_DIR + \"/*.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6dddea6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing vectors embeddings...\n",
      "Loading the most recent file of the vector embeddings: json/img_embed_06Jul2023_191005.json\n",
      "\n",
      "Done: number of imported vector embeddings = 1,473\n"
     ]
    }
   ],
   "source": [
    "print(\"Importing vectors embeddings...\")\n",
    "\n",
    "jsonfiles = [entry.name for entry in os.scandir(JSON_DIR) if entry.is_file()]\n",
    "jsonfiles = [f for f in jsonfiles if os.path.isfile(os.path.join(JSON_DIR, f))]\n",
    "\n",
    "# Get the most recent file\n",
    "modification_times = [\n",
    "    (f, os.path.getmtime(os.path.join(JSON_DIR, f))) for f in jsonfiles\n",
    "]\n",
    "modification_times.sort(key=lambda x: x[1], reverse=True)\n",
    "most_recent_file = JSON_DIR + \"/\" + modification_times[0][0]\n",
    "\n",
    "# Loading the most recent file\n",
    "print(f\"Loading the most recent file of the vector embeddings: {most_recent_file}\")\n",
    "\n",
    "with open(most_recent_file) as f:\n",
    "    list_emb = json.load(f)\n",
    "\n",
    "print(f\"\\nDone: number of imported vector embeddings = {len(list_emb):,}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c9de180a",
   "metadata": {},
   "source": [
    "## 5. <a name=\"chapt5\"></a> Gradio webapp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e52b482d",
   "metadata": {},
   "source": [
    "### Generic gradio elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "023f159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "footnote = \"Powered by Azure Computer Vision 4 (Florence)\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f003e83",
   "metadata": {},
   "source": [
    "### Visual Search using an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "232c9133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visual_search_from_image_app(image, list_emb=list_emb, topn=3):\n",
    "    \"\"\"\n",
    "    Function for visual search using an image for the gradio app\n",
    "    \"\"\"\n",
    "    # Reference image embeddding\n",
    "    nobackground_image = remove_background(image)\n",
    "    image_emb = image_embedding(nobackground_image)\n",
    "    # Comparing with all the images embeddings\n",
    "    results_list = [\n",
    "        get_cosine_similarity(image_emb, emb_image) for emb_image in list_emb\n",
    "    ]\n",
    "    # Topn results\n",
    "    df = pd.DataFrame(\n",
    "        list(zip(image_files, results_list)), columns=[\"image_file\", \"similarity\"]\n",
    "    )\n",
    "    df = df.sort_values(\"similarity\", ascending=False)\n",
    "    topn_list = df.nlargest(topn, \"similarity\")[\"image_file\"].tolist()\n",
    "\n",
    "    return topn_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9249c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "header_image = \"Visual Search with Azure Computer Vision (Florence) using an image\"\n",
    "images_examples = [\n",
    "    \"test/test1.jpg\",\n",
    "    \"test/test2.jpg\",\n",
    "    \"test/test3.jpg\",\n",
    "    \"test/test4.jpg\",\n",
    "]\n",
    "\n",
    "topn_list_images = [\"\"] * 3\n",
    "refimage = gr.components.Image(label=\"Your image:\", type=\"filepath\", shape=((200, 200)))\n",
    "list_img_results_prompt = [\n",
    "    gr.components.Image(\n",
    "        label=f\"Top {i+1}: {topn_list_images[i]}\", type=\"filepath\", shape=((200, 200))\n",
    "    )\n",
    "    for i in range(3)\n",
    "]\n",
    "\n",
    "webapp_image = gr.Interface(\n",
    "    visual_search_from_image_app,\n",
    "    refimage,\n",
    "    list_img_results_prompt,\n",
    "    title=header_image,\n",
    "    examples=images_examples,\n",
    "    theme=\"gstaff/sketch\",\n",
    "    article=footnote,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0519f592",
   "metadata": {},
   "source": [
    "### We can run this app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76eb2123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://61cf1121b92457e9fb.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://61cf1121b92457e9fb.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing background from the image using Azure Computer Vision 4.0...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "webapp_image.launch(share=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f665474",
   "metadata": {},
   "source": [
    "## 6. <a name=\"chapt6\"></a> Visual search using some text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c1ca665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visual_search_from_prompt_app(query, list_emb=list_emb, topn=3):\n",
    "    \"\"\"\n",
    "    Function for visual search using a prompt for the gradio app\n",
    "    \"\"\"\n",
    "    # Text Embedding of the prompt\n",
    "    text_emb = text_embedding(query)\n",
    "    # Comparing the Text embedding with all the images embeddings\n",
    "    results_list = [\n",
    "        get_cosine_similarity(text_emb, emb_image) for emb_image in list_emb\n",
    "    ]\n",
    "    # Top5 results\n",
    "    df = pd.DataFrame(\n",
    "        list(zip(image_files, results_list)), columns=[\"image_file\", \"similarity\"]\n",
    "    )\n",
    "    df = df.sort_values(\"similarity\", ascending=False)\n",
    "    topn_list = df.nlargest(topn, \"similarity\")[\"image_file\"].tolist()\n",
    "\n",
    "    return topn_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c20c31c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "header_prompt = \"Visual Search with Azure Computer Vision (Florence) using a prompt\"\n",
    "\n",
    "prompt_examples = [\n",
    "    \"a red dress\",\n",
    "    \"a red dress with long sleeves\",\n",
    "    \"blue shirt\",\n",
    "    \"shirt with Italian cities name\",\n",
    "    \"Ray-Ban\",\n",
    "    \"NYC cap\",\n",
    "]\n",
    "\n",
    "topn_list_prompt = [\"\"] * 3\n",
    "prompt = gr.components.Textbox(\n",
    "    lines=2,\n",
    "    label=\"What do you want to search?\",\n",
    "    placeholder=\"Enter your prompt for the visual search...\",\n",
    ")\n",
    "\n",
    "list_img_results_image = [\n",
    "    gr.components.Image(label=f\"Top {i+1}: {topn_list_prompt[i]}\", type=\"filepath\")\n",
    "    for i in range(3)\n",
    "]\n",
    "\n",
    "webapp_prompt = gr.Interface(\n",
    "    visual_search_from_prompt_app,\n",
    "    prompt,\n",
    "    list_img_results_image,\n",
    "    title=header_prompt,\n",
    "    examples=prompt_examples,\n",
    "    theme=\"gstaff/sketch\",\n",
    "    article=footnote,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "916f10f9",
   "metadata": {},
   "source": [
    "### We can run this app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99315f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "Running on public URL: https://d88128f48a488ee8d7.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://d88128f48a488ee8d7.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webapp_prompt.launch(share=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc466fb4",
   "metadata": {},
   "source": [
    "## Unified webapp\n",
    "### We can combine the 2 apps into a single one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf851f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/jupyter_env/lib/python3.8/site-packages/gradio/blocks.py:863: UserWarning: api_name predict already exists, using predict_1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://c59fd6302c8c0d36e6.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://c59fd6302c8c0d36e6.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 19;\n                var nbb_unformatted_code = \"# Combining the two gradio apps into one\\n\\nvisual_search_webapp = gr.TabbedInterface(\\n    [webapp_prompt, webapp_image],\\n    [\\n        \\\"1) Visual search from a prompt\\\", \\n        \\\"2) Visual search from an image\\\"\\n    ],\\n    css=\\\"body {background-color: black}\\\",\\n    theme=\\\"freddyaboulton/dracula_revamped\\\",  # Themes: https://huggingface.co/spaces/gradio/theme-gallery\\n)\\n\\nvisual_search_webapp.launch(share=True)\";\n                var nbb_formatted_code = \"# Combining the two gradio apps into one\\n\\nvisual_search_webapp = gr.TabbedInterface(\\n    [webapp_prompt, webapp_image],\\n    [\\\"1) Visual search from a prompt\\\", \\\"2) Visual search from an image\\\"],\\n    css=\\\"body {background-color: black}\\\",\\n    theme=\\\"freddyaboulton/dracula_revamped\\\",  # Themes: https://huggingface.co/spaces/gradio/theme-gallery\\n)\\n\\nvisual_search_webapp.launch(share=True)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Combining the two gradio apps into one\n",
    "\n",
    "visual_search_webapp = gr.TabbedInterface(\n",
    "    [webapp_prompt, webapp_image],\n",
    "    [\"1) Visual search from a prompt\", \"2) Visual search from an image\"],\n",
    "    css=\"body {background-color: black}\",\n",
    "    theme=\"freddyaboulton/dracula_revamped\",  # Themes: https://huggingface.co/spaces/gradio/theme-gallery\n",
    ")\n",
    "\n",
    "visual_search_webapp.launch(share=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a8cac5a",
   "metadata": {},
   "source": [
    "![Image](webapp1.jpg)\n",
    "\n",
    "![Image](webapp2.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e147aaba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
